{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9615b9e1",
   "metadata": {},
   "source": [
    "# TAO Image Multiclass Classification\n",
    "\n",
    "\n",
    "This example trained on https://github.com/everguard-inc/dataset_ppe/tree/ppe_multilabel_crops dataset with Nvidia pretrained Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac956bc1",
   "metadata": {},
   "source": [
    "# Set up env variables and map drives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "import os\n",
    "\n",
    "%env KEY='cXU2NzU4bHNpNHBpMzN2Z21mcmsxcDQzcDE6MGIwNDFmMDYtNmFjYy00YjJiLTliYWMtMDdjN2NjZjgwMDYx' #SET YOUR_NGC_KEY\n",
    "%env NUM_GPUS=1\n",
    "%env USER_EXPERIMENT_DIR=/workspace/tao-experiments/classification\n",
    "%env DATA_DOWNLOAD_DIR=/workspace/tao-experiments/data\n",
    "\n",
    "# Set this path if you don't run the notebook from the samples directory.\n",
    "# %env NOTEBOOK_ROOT=~/tao-samples/classification\n",
    "\n",
    "# Please define this local project directory that needs to be mapped to the TAO docker session.\n",
    "# The dataset expected to be present in $LOCAL_PROJECT_DIR/data, while the results for the steps\n",
    "# in this notebook will be stored at $LOCAL_PROJECT_DIR/classification\n",
    "# !PLEASE MAKE SURE TO UPDATE THIS PATH!.\n",
    "os.environ[\"LOCAL_PROJECT_DIR\"] = '/home/eg/auv/tao/tutorial/classification_v2' #SET YOUR LOCAL PATH\n",
    "\n",
    "os.environ[\"LOCAL_DATA_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"data\"\n",
    ")\n",
    "os.environ[\"LOCAL_EXPERIMENT_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"classification\"\n",
    ")\n",
    "\n",
    "# The sample spec files are present in the same path as the downloaded samples.\n",
    "os.environ[\"LOCAL_SPECS_DIR\"] = os.path.join(\n",
    "    os.getenv(\"NOTEBOOK_ROOT\", os.getcwd()),\n",
    "    \"specs\"\n",
    ")\n",
    "os.makedirs(os.environ[\"LOCAL_SPECS_DIR\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"LOCAL_DATA_DIR\"], exist_ok=True)\n",
    "\n",
    "%env SPECS_DIR=/workspace/tao-experiments/specs\n",
    "\n",
    "# Showing list of specification files.\n",
    "!ls -rlt $LOCAL_SPECS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"NOTEBOOK_ROOT\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $LOCAL_PROJECT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a7b13",
   "metadata": {},
   "source": [
    "**Directory above will be used for configs**\n",
    "\n",
    "The cell below maps the project directory on your local host to a workspace directory in the TAO docker instance, so that the data and the results are mapped from outside to inside of the docker instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping up the local directories to the TAO docker.\n",
    "import json\n",
    "import os\n",
    "mounts_file = os.path.expanduser(\"~/.tao_mounts.json\")\n",
    "\n",
    "# Define the dictionary with the mapped drives\n",
    "drive_map = {\n",
    "    \"Mounts\": [\n",
    "        # Mapping the data directory\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_PROJECT_DIR\"],\n",
    "            \"destination\": \"/workspace/tao-experiments\"\n",
    "        },\n",
    "        # Mapping the specs directory.\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_SPECS_DIR\"],\n",
    "            \"destination\": os.environ[\"SPECS_DIR\"]\n",
    "        },\n",
    "    ],\n",
    "    \"DockerOptions\":{\n",
    "        \"user\": \"{}:{}\".format(os.getuid(), os.getgid())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Writing the mounts file.\n",
    "with open(mounts_file, \"w\") as mfile:\n",
    "    json.dump(drive_map, mfile, indent=4)\n",
    "\n",
    "!cat ~/.tao_mounts.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198081e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP this cell IF you have already installed the TAO launcher.\n",
    "!pip3 install nvidia-pyindex\n",
    "!pip3 install nvidia-tao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7a416",
   "metadata": {},
   "source": [
    "If you followed installation advices from [Confluence Page](https://everguard.atlassian.net/wiki/spaces/EVERGUARD/pages/1644658744/Nvidia+TAO) your environment is ready.\n",
    "Check it with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a749686",
   "metadata": {},
   "source": [
    "Your data should be storred in LOCAL_DATA_DIR -> /workspace/tao-experiments/data. and has next structure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ae511",
   "metadata": {},
   "source": [
    "# Download pretrained models\n",
    "\n",
    "We will use NGC CLI to get the pre-trained models. You had to setup it earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f214e",
   "metadata": {},
   "source": [
    "List of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model list nvidia/tao/pretrained_classification:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c176f",
   "metadata": {},
   "source": [
    "Create directory for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c057c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mkdir -p $LOCAL_EXPERIMENT_DIR/<model_dir_name>/\n",
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/pretrained_resnet18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d104b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull pretrained model from NGC\n",
    "#ngc registry model download-version nvidia/tao/pretrained_classification:<model_name> --dest $LOCAL_EXPERIMENT_DIR/<model_dir_name>\n",
    "!ngc registry model download-version nvidia/tao/pretrained_classification:resnet18 --dest $LOCAL_EXPERIMENT_DIR/pretrained_resnet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $LOCAL_EXPERIMENT_DIR/pretrained_resnet18/pretrained_classification_vresnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf45e60",
   "metadata": {},
   "source": [
    "# Configuratin file\n",
    "\n",
    "[Conf file templates](https://docs.nvidia.com/tao/tao-toolkit/text/multitask_image_classification.html#preparing-the-input-data-structure) with detailed explanation of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be saved at specs directory\n",
    "!echo $LOCAL_SPECS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ab38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $LOCAL_SPECS_DIR/classification_spec.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a272f4",
   "metadata": {},
   "source": [
    "# Run TAO training\n",
    "Provide the sample spec file and the output directory location for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f37a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $SPECS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c99150",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao multitask_classification train\\\n",
    "        -e $SPECS_DIR/classification_spec.cfg\\\n",
    "        -r $USER_EXPERIMENT_DIR/output\\\n",
    "        -k $KEY --gpu_index 1 --gpus 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao multitask_classification inference\\\n",
    "                -m $USER_EXPERIMENT_DIR/output/weights/multitask_cls_resnet18_epoch_010.tlt\\\n",
    "                -i /workspace/tao-experiments/data/dataset_ppe/test/crops/val/rlg_f2b53921_2022-01-15_18-21-58_classes-in_harness-hardhat_unrecognized-in_vest-person_not_in_bucket_crop-01.jpg\\\n",
    "                -cm $USER_EXPERIMENT_DIR/output/class_mapping.json -k $KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a172fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread('/home/eg/auv/tao/tutorial/classification_v2/data/dataset_ppe/test/crops/val/rlg_f2b53921_2022-01-15_18-21-58_classes-in_harness-hardhat_unrecognized-in_vest-person_not_in_bucket_crop-01.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $LOCAL_PROJECT_DIR/classification/output/multitask_cls_training_log_resnet18.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f8335",
   "metadata": {},
   "source": [
    "# Evaluate trained models\n",
    "In this step, we assume that the training is complete and the model from the final epoch (`resnet_0<num>.tlt`) is available. If you would like to run evaluation on an earlier model, please edit the spec file at `$SPECS_DIR/classification_spec.cfg` to point to the intended model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ec37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao multitask_classification evaluate\\\n",
    "            -e $SPECS_DIR/classification_spec.cfg\\\n",
    "            -m $USER_EXPERIMENT_DIR/output/weights/multitask_cls_resnet18_epoch_010.tlt\\\n",
    "            -k $KEY \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014575ae",
   "metadata": {},
   "source": [
    "# Prune trained models\n",
    "* Specify pre-trained model\n",
    "* Equalization criterion\n",
    "* Threshold for pruning\n",
    "* Exclude prediction layer that you don't want pruned (e.g. predictions)\n",
    "\n",
    "Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold to use is depend on the dataset. A pth value 0.68 is just a starting point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec51d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $USER_EXPERIMENT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd255be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env EPOCH=010\n",
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/output/resnet_pruned\n",
    "!tao multitask_classification prune -m $USER_EXPERIMENT_DIR/output/weights/multitask_cls_resnet18_epoch_010.tlt \\\n",
    "                          -o $USER_EXPERIMENT_DIR/output/resnet_pruned/resnet18_nopool_bn_pruned.tlt \\\n",
    "                          -eq union \\\n",
    "                          -pth 0.6 \\\n",
    "                          -k $KEY \\\n",
    "                          --results_dir $USER_EXPERIMENT_DIR/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train pruned\n",
    "!tao multitask_classification train\\\n",
    "        -e $SPECS_DIR/classification_spec_pruned.cfg\\\n",
    "        -r $USER_EXPERIMENT_DIR/output_retrain\\\n",
    "        -k $KEY --gpu_index 1 --gpus 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22883e96",
   "metadata": {},
   "source": [
    "# Evaluate Pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao multitask_classification evaluate\\\n",
    "-e $SPECS_DIR/classification_spec_pruned.cfg\\\n",
    "-m $USER_EXPERIMENT_DIR/output/weights/multitask_cls_resnet18_epoch_005.tlt -k $KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e7ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
